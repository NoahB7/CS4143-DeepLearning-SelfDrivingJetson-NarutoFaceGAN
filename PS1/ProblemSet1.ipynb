{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.metrics import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder # iris dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ps1data1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , 0:len(data.columns)-1]\n",
    "Y = data.iloc[ : , len(data.columns)-1:len(data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalex = MinMaxScaler()\n",
    "scaley = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalex.fit_transform(X)\n",
    "Y = scaley.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(10,), dtype=\"float32\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(1, activation=\"linear\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 0.0093 - val_loss: 3.9674e-05\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.8504e-05 - val_loss: 3.6837e-05\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.6308e-05 - val_loss: 3.8940e-05\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.4423e-05 - val_loss: 4.3900e-05\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.2711e-05 - val_loss: 3.0601e-05\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.2570e-05 - val_loss: 2.7749e-05\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.9760e-05 - val_loss: 2.8453e-05\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.9912e-05 - val_loss: 2.5638e-05\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.8113e-05 - val_loss: 2.8662e-05\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.0505e-05 - val_loss: 2.2931e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x293230beaf0>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=10, batch_size=128, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 2.2742e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2742406144971028e-05"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ps1data2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , 0:len(data.columns)-1]\n",
    "Y = data.iloc[ : , len(data.columns)-1:len(data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalex = MinMaxScaler()\n",
    "scaley = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalex.fit_transform(X)\n",
    "Y = scaley.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(10,), dtype=\"float32\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(1, activation=\"linear\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29323bdc610>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=10, batch_size=128, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002228186698630452"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test.iloc[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048002943\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled up to original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2189280.8\n"
     ]
    }
   ],
   "source": [
    "print(scaley.inverse_transform(prediction)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>509.0</th>\n",
       "      <th>576.0</th>\n",
       "      <th>546.0</th>\n",
       "      <th>3974.0</th>\n",
       "      <th>2706.0</th>\n",
       "      <th>3595.0</th>\n",
       "      <th>383.0</th>\n",
       "      <th>1129.0</th>\n",
       "      <th>532.0</th>\n",
       "      <th>546.0.1</th>\n",
       "      <th>...</th>\n",
       "      <th>19.0.4</th>\n",
       "      <th>2126.0</th>\n",
       "      <th>3304.0</th>\n",
       "      <th>114.0</th>\n",
       "      <th>621.0</th>\n",
       "      <th>1048.0</th>\n",
       "      <th>146.0</th>\n",
       "      <th>16.0.1</th>\n",
       "      <th>239.0</th>\n",
       "      <th>324.03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>877.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>3945.0</td>\n",
       "      <td>3836.0</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>4271.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>2085.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>2833.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1849.0</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>3239.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>1385.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>3824.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2798.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2611.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>766.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4744.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>2285.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>2098.0</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>3984.0</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>800.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1669.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>3063.0</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>3434.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2711.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>824.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2485.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2533.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>2577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>1354.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1857.0</td>\n",
       "      <td>2761.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3545.0</td>\n",
       "      <td>3691.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>2589.0</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>3192.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>3676.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>970.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>2532.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3205.0</td>\n",
       "      <td>4119.0</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1706.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       509.0   576.0   546.0   3974.0   2706.0   3595.0   383.0   1129.0  \\\n",
       "0      877.0  1810.0   491.0   3074.0   3945.0   3836.0  2540.0   1853.0   \n",
       "1     1987.0  1753.0   468.0   3337.0   2668.0   1266.0    15.0   2819.0   \n",
       "2     1849.0  2813.0   391.0   1755.0   2417.0   1180.0  1402.0   3239.0   \n",
       "3      239.0  1854.0   138.0   1984.0   3824.0    102.0  2798.0   1548.0   \n",
       "4      766.0  1555.0   458.0   3220.0    216.0   4744.0     7.0   3505.0   \n",
       "...      ...     ...     ...      ...      ...      ...     ...      ...   \n",
       "9994  2098.0  3575.0   203.0    132.0   2705.0   3984.0  2654.0   1597.0   \n",
       "9995  1669.0  3852.0    42.0   4427.0   1014.0   3063.0  1657.0   3434.0   \n",
       "9996   824.0  3664.0   483.0     50.0    451.0    785.0  2485.0   1551.0   \n",
       "9997  1857.0  2761.0     6.0   3545.0   3691.0   2623.0  2589.0   2998.0   \n",
       "9998   970.0  1752.0   522.0    646.0    570.0   3570.0  2532.0   3371.0   \n",
       "\n",
       "       532.0   546.0.1  ...   19.0.4   2126.0   3304.0   114.0   621.0  \\\n",
       "0     1009.0     888.0  ...     18.0   1643.0   4271.0  1089.0   938.0   \n",
       "1     1455.0     826.0  ...     41.0   3624.0    420.0   106.0   487.0   \n",
       "2      251.0     448.0  ...      9.0   2809.0   1612.0   188.0  1739.0   \n",
       "3       23.0     808.0  ...     45.0   2371.0   2618.0   706.0   609.0   \n",
       "4     1474.0    1435.0  ...     39.0    145.0    559.0    36.0  1465.0   \n",
       "...      ...       ...  ...      ...      ...      ...     ...     ...   \n",
       "9994  1645.0     786.0  ...     60.0   3892.0   2109.0  1216.0  1055.0   \n",
       "9995   886.0     318.0  ...     49.0    685.0   1497.0  1455.0  1672.0   \n",
       "9996   768.0     344.0  ...     53.0   2533.0   1517.0   880.0  2577.0   \n",
       "9997   891.0    1473.0  ...     50.0   1114.0   3192.0   321.0  1468.0   \n",
       "9998  1195.0     345.0  ...     47.0   3205.0   4119.0  1461.0  1303.0   \n",
       "\n",
       "       1048.0   146.0   16.0.1   239.0   324.03  \n",
       "0       480.0   302.0      4.0   906.0  2085.70  \n",
       "1       182.0   472.0     75.0  2073.0  2833.40  \n",
       "2      1991.0   338.0     75.0  1154.0  1385.15  \n",
       "3       437.0   375.0    155.0    72.0  2611.66  \n",
       "4      1092.0    23.0      4.0  2302.0  2285.97  \n",
       "...       ...     ...      ...     ...      ...  \n",
       "9994   1076.0    82.0      2.0   509.0   800.42  \n",
       "9995   1573.0   342.0    174.0   675.0  2711.37  \n",
       "9996      3.0   175.0    121.0  1088.0  1354.40  \n",
       "9997   1916.0   105.0      1.0   751.0  3676.06  \n",
       "9998    632.0   123.0    161.0  1584.0  1706.72  \n",
       "\n",
       "[9999 rows x 1001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ps1data3.txt\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , 0:len(data.columns)-1]\n",
    "Y = data.iloc[ : , len(data.columns)-1:len(data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalex = MinMaxScaler()\n",
    "scaley = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalex.fit_transform(X)\n",
    "Y = scaley.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 32,065\n",
      "Trainable params: 32,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(1000,), dtype=\"float32\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(1, activation=\"linear\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57/57 [==============================] - 1s 5ms/step - loss: 0.0551 - val_loss: 0.0325\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0266\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0273\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0250\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0226\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0224\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0176\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0174\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0200\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0191\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0194\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0176\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0290\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0172\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0170\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0191\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0178\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0173\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0182\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0169\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0170\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0182\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0172\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0171\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0177\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0193\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0186\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0179\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0177\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0189\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0174\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0174\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0171\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0173\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0195\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0173\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0197\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0200\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0169\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0174\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0170\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0182\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0171\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0186\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0173\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0179\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0170\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0175\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0210\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0216\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0212\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0176\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0178\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0174\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0213\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0174\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0201\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0195\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0174\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0173\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0174\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0174\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0175\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0203\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0174\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0189\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0186\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0175\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0205\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0195\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0228\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0180\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0181\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0178\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2573a783f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=100, batch_size=128, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020743288099765778"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07029939617496 41\n",
      "2.03844708824181 63\n",
      "2.153975899098441 82\n",
      "11.706265948712826 101\n",
      "12.860410548746586 129\n",
      "2.192574010696262 148\n",
      "2.0009046476334333 151\n",
      "2.0274893956957385 222\n",
      "2.0078923739492893 225\n",
      "2.31528353667818 476\n",
      "2.129663037834689 499\n",
      "2.0330728499684483 720\n",
      "2.023197618982522 722\n",
      "2.0733554986072704 764\n",
      "2.0569445767905563 859\n",
      "2.0585444010794163 878\n",
      "2.027658084174618 926\n",
      "2.0906489703047555 955\n",
      "2.0239898548461497 1000\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()[0]\n",
    "length = len(weights)\n",
    "for i in range(0, length):\n",
    "    if(sum(abs(weights[i][:])) > 2):\n",
    "        print(sum(abs(weights[i])),i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature 101 and feature 129 had the most impact on the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"irisdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , 0:len(data.columns)-1]\n",
    "Y = data.iloc[ : , len(data.columns)-1:len(data.columns)]\n",
    "# for manual scaling later in get_flower_type method\n",
    "columns = X.columns\n",
    "maxs = [max(X[columns[0]]), max(X[columns[1]]), max(X[columns[2]]), max(X[columns[3]])]\n",
    "mins = [min(X[columns[0]]),  min(X[columns[1]]), min(X[columns[2]]), min(X[columns[3]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalex = MinMaxScaler()\n",
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalex.fit_transform(X)\n",
    "Y = encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(4,), dtype=\"float32\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(32, activation=\"sigmoid\") )\n",
    "model.add( Dense(3, activation=\"softmax\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tensorflow.keras.metrics.* to use metrics such as precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=\"adam\", loss=\"mse\" , metrics=[\"accuracy\", Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.2195 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2179 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2191 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2202 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2189 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2220 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2188 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2232 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2186 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2239 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2185 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2240 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2183 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2238 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2182 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2234 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2180 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2227 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2178 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2220 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2176 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2213 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2174 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2206 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2172 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2200 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2170 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2168 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2192 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2166 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2191 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2164 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2190 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2162 - accuracy: 0.3645 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2192 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2160 - accuracy: 0.3925 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2193 - val_accuracy: 0.4167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2158 - accuracy: 0.4206 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2196 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2156 - accuracy: 0.5701 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2198 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2153 - accuracy: 0.6449 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2201 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2151 - accuracy: 0.6822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2203 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2149 - accuracy: 0.6822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2204 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2146 - accuracy: 0.6822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2204 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2144 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2203 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2141 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2201 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2139 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2199 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2136 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2196 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2133 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2193 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2131 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2190 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2128 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2187 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2125 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2184 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2122 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2182 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2119 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2180 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2116 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2179 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2113 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2178 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2110 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2177 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2106 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2103 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2100 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2096 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2175 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2092 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2174 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2089 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2173 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2085 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2171 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2081 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2169 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2077 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2167 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2073 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2164 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2069 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2161 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2065 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2159 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2060 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2156 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2056 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2154 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2051 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2151 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2046 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2149 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2042 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2147 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2037 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2144 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2032 - accuracy: 0.6916 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2142 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2027 - accuracy: 0.6822 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2140 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2021 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2138 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2016 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2135 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2010 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2133 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2005 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2130 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1999 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2127 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1993 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2124 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1987 - accuracy: 0.6729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2120 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1981 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2117 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1975 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2113 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1969 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2109 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1962 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2106 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1956 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2102 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1949 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2098 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1942 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2094 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1935 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2090 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1928 - accuracy: 0.6636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2086 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1920 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2082 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1913 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2078 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1906 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2074 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1898 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2069 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1890 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2065 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1882 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2060 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1874 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2055 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1866 - accuracy: 0.6542 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1858 - accuracy: 0.6542 - precision: 1.0000 - recall: 0.0093 - val_loss: 0.2045 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1849 - accuracy: 0.6542 - precision: 1.0000 - recall: 0.0187 - val_loss: 0.2039 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1841 - accuracy: 0.6542 - precision: 1.0000 - recall: 0.0187 - val_loss: 0.2034 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1832 - accuracy: 0.6542 - precision: 1.0000 - recall: 0.0374 - val_loss: 0.2028 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1824 - accuracy: 0.6636 - precision: 1.0000 - recall: 0.0561 - val_loss: 0.2023 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1815 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.0748 - val_loss: 0.2017 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1806 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.1215 - val_loss: 0.2011 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1797 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.1402 - val_loss: 0.2005 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1788 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.2243 - val_loss: 0.1999 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1779 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.2523 - val_loss: 0.1993 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1769 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.2617 - val_loss: 0.1987 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1760 - accuracy: 0.6729 - precision: 1.0000 - recall: 0.2710 - val_loss: 0.1981 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1750 - accuracy: 0.6822 - precision: 1.0000 - recall: 0.2991 - val_loss: 0.1974 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1741 - accuracy: 0.6916 - precision: 1.0000 - recall: 0.2991 - val_loss: 0.1968 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1731 - accuracy: 0.7103 - precision: 1.0000 - recall: 0.2991 - val_loss: 0.1961 - val_accuracy: 0.5833 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1722 - accuracy: 0.7196 - precision: 1.0000 - recall: 0.3084 - val_loss: 0.1954 - val_accuracy: 0.5833 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1712 - accuracy: 0.7290 - precision: 1.0000 - recall: 0.3084 - val_loss: 0.1947 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1702 - accuracy: 0.7383 - precision: 1.0000 - recall: 0.3178 - val_loss: 0.1940 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1692 - accuracy: 0.7570 - precision: 1.0000 - recall: 0.3178 - val_loss: 0.1933 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1682 - accuracy: 0.7850 - precision: 1.0000 - recall: 0.3178 - val_loss: 0.1926 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1673 - accuracy: 0.7944 - precision: 1.0000 - recall: 0.3178 - val_loss: 0.1919 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1663 - accuracy: 0.8037 - precision: 1.0000 - recall: 0.3178 - val_loss: 0.1911 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1653 - accuracy: 0.8131 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1904 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1643 - accuracy: 0.8224 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1896 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1633 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1889 - val_accuracy: 0.8333 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1623 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1881 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1613 - accuracy: 0.8505 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1874 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1603 - accuracy: 0.8692 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1866 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1593 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1858 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1583 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1850 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1573 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1842 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1563 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1834 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1553 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1826 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1543 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1818 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1533 - accuracy: 0.8224 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1810 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1523 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1802 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1514 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1794 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1504 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1786 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1494 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1778 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1485 - accuracy: 0.8505 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1770 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 0.8505 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1761 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1466 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1753 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1457 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1745 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1447 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1737 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1438 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1729 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1429 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1720 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1420 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1712 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1411 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1704 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1402 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1696 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1393 - accuracy: 0.8411 - precision: 1.0000 - recall: 0.3271 - val_loss: 0.1687 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1384 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3364 - val_loss: 0.1679 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1375 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3364 - val_loss: 0.1671 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1367 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3364 - val_loss: 0.1663 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1358 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3364 - val_loss: 0.1655 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1350 - accuracy: 0.8318 - precision: 1.0000 - recall: 0.3458 - val_loss: 0.1646 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1341 - accuracy: 0.8505 - precision: 1.0000 - recall: 0.3458 - val_loss: 0.1638 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1333 - accuracy: 0.8505 - precision: 1.0000 - recall: 0.3551 - val_loss: 0.1630 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1324 - accuracy: 0.8598 - precision: 1.0000 - recall: 0.3645 - val_loss: 0.1622 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.8598 - precision: 1.0000 - recall: 0.3645 - val_loss: 0.1614 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.0833\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1308 - accuracy: 0.8785 - precision: 1.0000 - recall: 0.3832 - val_loss: 0.1606 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1300 - accuracy: 0.8785 - precision: 1.0000 - recall: 0.4112 - val_loss: 0.1597 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1292 - accuracy: 0.8785 - precision: 1.0000 - recall: 0.4112 - val_loss: 0.1589 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1284 - accuracy: 0.8785 - precision: 1.0000 - recall: 0.4112 - val_loss: 0.1581 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1276 - accuracy: 0.8785 - precision: 1.0000 - recall: 0.4206 - val_loss: 0.1573 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1268 - accuracy: 0.8879 - precision: 1.0000 - recall: 0.4206 - val_loss: 0.1565 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1261 - accuracy: 0.8879 - precision: 1.0000 - recall: 0.4299 - val_loss: 0.1557 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1253 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4393 - val_loss: 0.1549 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4579 - val_loss: 0.1541 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1238 - accuracy: 0.9159 - precision: 1.0000 - recall: 0.4766 - val_loss: 0.1533 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1230 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4766 - val_loss: 0.1525 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1223 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4860 - val_loss: 0.1517 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.1667\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1216 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4860 - val_loss: 0.1509 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1208 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4953 - val_loss: 0.1501 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1201 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.4953 - val_loss: 0.1493 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1194 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1485 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1187 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1477 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1180 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1469 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.2500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1173 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1461 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1166 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1453 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1445 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1152 - accuracy: 0.9065 - precision: 1.0000 - recall: 0.5140 - val_loss: 0.1438 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1145 - accuracy: 0.9159 - precision: 1.0000 - recall: 0.5234 - val_loss: 0.1430 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9159 - precision: 1.0000 - recall: 0.5234 - val_loss: 0.1422 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1131 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5327 - val_loss: 0.1414 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1124 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1406 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.3333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1118 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1399 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1111 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1391 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1104 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1383 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1098 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1091 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1368 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1085 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1360 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1078 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5421 - val_loss: 0.1352 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1072 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5514 - val_loss: 0.1345 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1065 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5514 - val_loss: 0.1337 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1059 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5514 - val_loss: 0.1329 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1053 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1322 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.4167\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1046 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1314 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1040 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1306 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1034 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1299 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1027 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1291 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1021 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1284 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1015 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5607 - val_loss: 0.1276 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1009 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5794 - val_loss: 0.1269 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1003 - accuracy: 0.9346 - precision: 1.0000 - recall: 0.5794 - val_loss: 0.1261 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0996 - accuracy: 0.9252 - precision: 1.0000 - recall: 0.5888 - val_loss: 0.1254 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0990 - accuracy: 0.9252 - precision: 0.9851 - recall: 0.6168 - val_loss: 0.1246 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0984 - accuracy: 0.9252 - precision: 0.9853 - recall: 0.6262 - val_loss: 0.1239 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0978 - accuracy: 0.9252 - precision: 0.9855 - recall: 0.6355 - val_loss: 0.1231 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.5833\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0972 - accuracy: 0.9252 - precision: 0.9861 - recall: 0.6636 - val_loss: 0.1224 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.6667\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0966 - accuracy: 0.9252 - precision: 0.9863 - recall: 0.6729 - val_loss: 0.1216 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.6667\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0960 - accuracy: 0.9252 - precision: 0.9872 - recall: 0.7196 - val_loss: 0.1209 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.7500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0954 - accuracy: 0.9252 - precision: 0.9872 - recall: 0.7196 - val_loss: 0.1201 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.7500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0948 - accuracy: 0.9252 - precision: 0.9873 - recall: 0.7290 - val_loss: 0.1194 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0942 - accuracy: 0.9252 - precision: 0.9877 - recall: 0.7477 - val_loss: 0.1187 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0937 - accuracy: 0.9252 - precision: 0.9756 - recall: 0.7477 - val_loss: 0.1179 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0931 - accuracy: 0.9252 - precision: 0.9762 - recall: 0.7664 - val_loss: 0.1172 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0925 - accuracy: 0.9252 - precision: 0.9770 - recall: 0.7944 - val_loss: 0.1165 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0919 - accuracy: 0.9252 - precision: 0.9770 - recall: 0.7944 - val_loss: 0.1157 - val_accuracy: 0.9167 - val_precision: 1.0000 - val_recall: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2573b52a640>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=200, batch_size=128, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 0.9000 - precision: 1.0000 - recall: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07336597144603729, 0.8999999761581421, 1.0, 0.8666666746139526]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: iris\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caveat is the data has to be loaded at some point as well so we know what the max and min is so we can scale the input\n",
    "# since the weights are meant for scaled data\n",
    "def get_flower_type(arg1,arg2,arg3,arg4):\n",
    "#     flower labels\n",
    "    labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "#     load model\n",
    "    localmodel = load_model('iris')\n",
    "#     scale input\n",
    "    inputx = [[arg1,arg2,arg3,arg4]]\n",
    "    for i in range(0,3):\n",
    "        inputx[0][i] = (inputx[0][i] - mins[i]) / (maxs[i] - mins[i])\n",
    "    prediction = localmodel.predict(inputx)\n",
    "#     find highest scoring label\n",
    "    maximum = 0\n",
    "    index = 0;\n",
    "    for i in range(0,2):\n",
    "        if(prediction[0][i] > maximum):\n",
    "            maximum = prediction[0][i]\n",
    "            index = i\n",
    "    return labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-versicolor'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flower_type(6.5,3.0,5.5,1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ps1data1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , 0:len(data.columns)-1]\n",
    "Y = data.iloc[ : , len(data.columns)-1:len(data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalex = MinMaxScaler()\n",
    "scaley = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scalex.fit_transform(X)\n",
    "Y = scaley.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(10,), dtype=\"float32\") )\n",
    "model.add( Dense(10, activation=\"relu\") )\n",
    "model.add( Dense(10, activation=\"relu\") )\n",
    "model.add( Dense(1, activation=\"linear\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 0.0253 - val_loss: 0.0010\n",
      "Epoch 2/2\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 4.4366e-04 - val_loss: 2.0065e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29310507310>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=2, batch_size=128, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 1.8462e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00018462225852999836"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ps1model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ps1model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 231\n",
      "Trainable params: 231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "diskmodel = load_model('ps1model')\n",
    "diskmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 461\n",
      "Trainable params: 461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "diskmodel.pop()\n",
    "diskmodel.add( Dense(20, activation='relu') )\n",
    "diskmodel.add( Dense(1, activation='linear') )\n",
    "diskmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "diskmodel.compile( optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "563/563 [==============================] - 2s 2ms/step - loss: 0.0165 - val_loss: 1.1907e-04\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 8.7736e-05 - val_loss: 7.4093e-05\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 6.1058e-05 - val_loss: 5.4431e-05\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 4.6723e-05 - val_loss: 4.6801e-05\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.7509e-05 - val_loss: 3.5693e-05\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 3.2008e-05 - val_loss: 3.0444e-05\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.7985e-05 - val_loss: 2.8913e-05\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.5637e-05 - val_loss: 2.7139e-05\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.4893e-05 - val_loss: 2.3310e-05\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 1s 2ms/step - loss: 2.4488e-05 - val_loss: 2.4107e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29320970af0>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diskmodel.fit( x_train, y_train, epochs=10, batch_size=128, validation_split=0.1 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
